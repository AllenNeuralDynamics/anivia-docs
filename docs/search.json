[
  {
    "objectID": "guides_intro.html",
    "href": "guides_intro.html",
    "title": "Guides",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nauthor\n\n\n\n\n\n\nGuide to annotating in 3D\n\n\n \n\n\n\n\nImport and exporting annotations\n\n\n \n\n\n\n\nLabeling multiple animals\n\n\n \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Guides"
    ]
  },
  {
    "objectID": "tutorial_anipose.html",
    "href": "tutorial_anipose.html",
    "title": "Tutorial: Annotate Anipose format in 3D",
    "section": "",
    "text": "It supports an ad-hoc format that should be easy to get from your anipose labeled-data. The structure is:\n\nmain folder with subfolders per camera\nfiles in main folder\n\nCollectedData.csv - file with annotations, can be generated from group of DLC files\ncalibration.toml - calibration file generated by anipose\nconfig.toml - should have camera cropping offsets (if any)\n\nIf you upgrade anipose to latest version (1.1.2), running anipose extract-frames will now generate this format.\nSee example zip above",
    "crumbs": [
      "Getting started",
      "Tutorial: Annotate Anipose format in 3D"
    ]
  },
  {
    "objectID": "tutorial_anipose.html#format-for-anipose-3d-labeling-data",
    "href": "tutorial_anipose.html#format-for-anipose-3d-labeling-data",
    "title": "Tutorial: Annotate Anipose format in 3D",
    "section": "",
    "text": "It supports an ad-hoc format that should be easy to get from your anipose labeled-data. The structure is:\n\nmain folder with subfolders per camera\nfiles in main folder\n\nCollectedData.csv - file with annotations, can be generated from group of DLC files\ncalibration.toml - calibration file generated by anipose\nconfig.toml - should have camera cropping offsets (if any)\n\nIf you upgrade anipose to latest version (1.1.2), running anipose extract-frames will now generate this format.\nSee example zip above",
    "crumbs": [
      "Getting started",
      "Tutorial: Annotate Anipose format in 3D"
    ]
  },
  {
    "objectID": "tutorial_anipose.html#to-label-in-3d",
    "href": "tutorial_anipose.html#to-label-in-3d",
    "title": "Tutorial: Annotate Anipose format in 3D",
    "section": "To label in 3D:",
    "text": "To label in 3D:\n\nOpen anivia: https://lambdaloop.com/anivia/\nIn menu: Import &gt; “Load Anipose Dataset”\nSelect the main folder (which contains all the camera subfolders)\nClick “Toggle 3D annotation” button\nYou should see multiple views and points should be green/red\nAnnotation proceeds same as in 2D\n\nSee “Help &gt; Getting Started”\nIf you don’t have any bodyparts, specify them in Project &gt; Edit bodyparts\n\nWhen done, in menu do: Export &gt; Export Annotations (Anipose format)\nSave the file as “CollectedData.csv” in the main Anipose folder\n\nyou may need to change settings in your browser to make it prompt where to save your downloaded file",
    "crumbs": [
      "Getting started",
      "Tutorial: Annotate Anipose format in 3D"
    ]
  },
  {
    "objectID": "tutorial_anipose.html#d-annotation-features",
    "href": "tutorial_anipose.html#d-annotation-features",
    "title": "Tutorial: Annotate Anipose format in 3D",
    "section": "3D annotation features",
    "text": "3D annotation features\n\nSee all the views at once!\nYou can toggle to another view by clicking on it\nPoints are colored by reprojection error: green is low error, red is high error.\n\nIt’s the mean error across all views, per point. You’ll have to discern which view(s) are causing the issue.\n\nProject points based on other views! (this feature feels magical to me)\n\nDelete points you want projected (select and press “d” or click the “x” at the top)\nClick “Project missing points”\nAny point visible in 2+ other views will be projected onto current view",
    "crumbs": [
      "Getting started",
      "Tutorial: Annotate Anipose format in 3D"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Anivia: Animal image annotator",
    "section": "",
    "text": "Anivia is a new web tool intended specifically for annotation of animal keypoints from images in both 2D and 3D.\nYou can find it here: https://lambdaloop.com/anivia\nKey features:\n\nRuns directly in a browser, no installation needed\nSupport for DeepLabCut, SLEAP, Lightning Pose, and Anipose formats\nImages are loaded in your browser locally\nFor 3D annotation: see reprojection error, project to different viwes, and more!\n\nTo get started, try following one of the tutorials for DeepLabCut (2D) or Anipose (3D) annotation datasets. You may also want check the guides for help with a specific workflow.\n\nAnivia is derived from the VGG Image Annotator (Version 2), by Abhishek Dutta, Akush Gupta, Andrew Zisserman and VIA contributors.",
    "crumbs": [
      "Getting started"
    ]
  },
  {
    "objectID": "guide_import_export.html",
    "href": "guide_import_export.html",
    "title": "Import and exporting annotations",
    "section": "",
    "text": "This is a guide to walk you through the steps of importing and exporting various annotation formats.",
    "crumbs": [
      "Guides",
      "Import and exporting annotations"
    ]
  },
  {
    "objectID": "guide_import_export.html#importing-annotations",
    "href": "guide_import_export.html#importing-annotations",
    "title": "Import and exporting annotations",
    "section": "Importing annotations",
    "text": "Importing annotations\n\nfrom DeepLabCut\nTo import a DeepLabCut dataset, follow the steps below. Note that you can only label one folder at a time.\n\nIn the menu, click on: Import &gt; Load DeepLabCut dataset\nNavigate to your DeepLabCut project\nGo within the labeled-data\nSelect a folder and click “Upload”\n\nIf there are no labels yet, you may need to specify bodyparts (below). Note: Due to no available libraries to parse pytables in javascript, just the h5 file with labels (not images) is sent to server to convert it to a csv to parse.\n\n\nfrom Lightning Pose\nTo import a Lightning Pose dataset, follow the steps below.\n\nIn the menu, click on: Import &gt; Load Lightning Pose dataset\nNavigate to your folder which contains “CollectedData.csv”\nSelect that folder and click “Upload”\n\n\n\nfrom SLEAP\nTo import a SLEAP dataset, follow these steps:\n\nIn the menu, click on: Import &gt; Load SLEAP dataset (SLP file)\nSelect your slp file and select “Upload”\n\nNote that SLP file must have the images padded with zeros to account for the javascript h5 loading library. This is already in the latest SLEAP code and will be available in future SLEAP releases. For now, you can use this python script to pad your video items.",
    "crumbs": [
      "Guides",
      "Import and exporting annotations"
    ]
  },
  {
    "objectID": "guide_import_export.html#exporting-annotations",
    "href": "guide_import_export.html#exporting-annotations",
    "title": "Import and exporting annotations",
    "section": "Exporting annotations",
    "text": "Exporting annotations\n\nto DeepLabCut\nTo export your annotations to DeepLabCut, follow these steps:\n\nIn the menu, click on: Export &gt; Export Annotations (DeepLabCut format)\nSave your file as “CollectedData_SCORER.h5” within the folder within labeled-data that you imported Replace SCORER above with the actual scorer name you specified at the top of your DeepLabCut config.yaml\n\nNote: Similarly to importing, due to limitations on h5 libraries in javascript, the labels are sent to server to convert them to generate an h5 file. Again, no images are ever sent out of your machine, only labels.\n\n\nto Lightning Pose\nTo export your annotations to Lightning Pose, follow these steps:\n\nIn the menu, click on: Export &gt; Export Annotations (Lightning Pose format)\nSave your file as “CollectedData.csv” within the folder you imported\n\n\n\nto SLEAP\nTo export your annotations to Lightning Pose, follow these steps:\n\nIn the menu, click on: Export &gt; Export Annotations (SLP format)\nSave your slp file wherever.\n\nIt might take a bit of time (less than a minute) to generate the SLP file for export.",
    "crumbs": [
      "Guides",
      "Import and exporting annotations"
    ]
  },
  {
    "objectID": "explanation_choices_anivia.html",
    "href": "explanation_choices_anivia.html",
    "title": "Choices made in designing Anivia",
    "section": "",
    "text": "choices to write about\nproject choices\n\nwhy i perceived other tools as insufficient\nextending VGG VIA instead of writing from scratch\n\ndisplay of information\n\nhow to display reprojection error\nUI for projecting points\n\ntechnical choices\n\nimporting files vs server\nserver for deeplabcut loading\nformat for Anipose 3D annotation",
    "crumbs": [
      "Explanation",
      "Choices made in designing Anivia"
    ]
  },
  {
    "objectID": "guide_annotating_in_3d.html",
    "href": "guide_annotating_in_3d.html",
    "title": "Guide to annotating in 3D",
    "section": "",
    "text": "See all the views at once!\nYou can toggle to another view by clicking on it\nPoints are colored by reprojection error: green is low error, red is high error.\n\nIt’s the mean error across all views, per point. You’ll have to discern which view(s) are causing the issue.\n\nProject points based on other views! (this feature feels magical to me)\n\nDelete points you want projected (select and press “d” or click the “x” at the top)\nClick “Project missing points”\nAny point visible in 2+ other views will be projected onto current view",
    "crumbs": [
      "Guides",
      "Guide to annotating in 3D"
    ]
  },
  {
    "objectID": "guide_labeling_multiple_animals.html",
    "href": "guide_labeling_multiple_animals.html",
    "title": "Labeling multiple animals",
    "section": "",
    "text": "Anivia supports labeling multiple animals, but only if you export to a SLEAP file currently.\nThe interface focuses on one animal “instance” at a time. By default when you click to place points it places them in instance 0.\nHere is how you navigate the instance interface:\n\n“i” for new instance (or circle plus in toolbar)\n“u” to delete an instance (or circle minus in toolbar)\nup and down arrows to switch between instances (or circle up and down in toolbar, or just click on a point from that instance)",
    "crumbs": [
      "Guides",
      "Labeling multiple animals"
    ]
  },
  {
    "objectID": "ref_formats.html",
    "href": "ref_formats.html",
    "title": "Supported formats",
    "section": "",
    "text": "TODO: description of each format supported",
    "crumbs": [
      "Reference",
      "Supported formats"
    ]
  },
  {
    "objectID": "ref_formats.html#deeplabcut-format",
    "href": "ref_formats.html#deeplabcut-format",
    "title": "Supported formats",
    "section": "DeepLabCut format",
    "text": "DeepLabCut format",
    "crumbs": [
      "Reference",
      "Supported formats"
    ]
  },
  {
    "objectID": "ref_formats.html#lightning-pose-format",
    "href": "ref_formats.html#lightning-pose-format",
    "title": "Supported formats",
    "section": "Lightning Pose format",
    "text": "Lightning Pose format",
    "crumbs": [
      "Reference",
      "Supported formats"
    ]
  },
  {
    "objectID": "ref_formats.html#sleap-format",
    "href": "ref_formats.html#sleap-format",
    "title": "Supported formats",
    "section": "SLEAP format",
    "text": "SLEAP format",
    "crumbs": [
      "Reference",
      "Supported formats"
    ]
  },
  {
    "objectID": "ref_formats.html#anipose-format",
    "href": "ref_formats.html#anipose-format",
    "title": "Supported formats",
    "section": "Anipose format",
    "text": "Anipose format",
    "crumbs": [
      "Reference",
      "Supported formats"
    ]
  },
  {
    "objectID": "tutorial_deeplabcut.html",
    "href": "tutorial_deeplabcut.html",
    "title": "Tutorial: Annotate a DeepLabCut dataset",
    "section": "",
    "text": "Welcome! In this tutorial, we will import a DeepLabCut dataset, inspect it, test out annotation, and export it again.",
    "crumbs": [
      "Getting started",
      "Tutorial: Annotate a DeepLabCut dataset"
    ]
  },
  {
    "objectID": "tutorial_deeplabcut.html#an-example-dataset",
    "href": "tutorial_deeplabcut.html#an-example-dataset",
    "title": "Tutorial: Annotate a DeepLabCut dataset",
    "section": "An example dataset",
    "text": "An example dataset\nIn this tutorial, we will work with the mouse reaching dataset provided as an example in DeepLabCut repository. You may download the dataset from our mirror on google drive. Alternatively, you may download the DeepLabCut repository from github directly and then navigate to the example in the “examples/Reaching-Mackenzie-2018-08-30”.\nThis dataset is from Mathis et al, “Somatosensory Cortex Plays an Essential Role in Forelimb Motor Adaptation in Mice”, Neuron, 2017.",
    "crumbs": [
      "Getting started",
      "Tutorial: Annotate a DeepLabCut dataset"
    ]
  },
  {
    "objectID": "tutorial_deeplabcut.html#importing-annotations",
    "href": "tutorial_deeplabcut.html#importing-annotations",
    "title": "Tutorial: Annotate a DeepLabCut dataset",
    "section": "Importing annotations",
    "text": "Importing annotations\nOpen Anivia, then follow the steps below to import this DeepLabCut dataset.\n\nIn the menu, click on: Import &gt; Load DeepLabCut dataset\nNavigate to your DeepLabCut project: Reaching-Mackenzie-2018-08-30\nGo within the “labeled-data” folder\nSelect the folder “reachingvideo1” and click “Upload”\nConfirm you want to “upload” the files\n\n\n\n\n\n\n\nNote\n\n\n\nThe upload confirmation just means the folder is sent to the browser, not to a server. Everything is kept locally, with one notable exception below.\nFor the DeepLabCut h5 annotation specifically, the h5 file with labels must be sent to a server to convert it to a csv to parse due to limitations in javascript.\n\n\nIf you follow these steps correctly, your interface should look like the following image.\n\n\n\nThe Anivia interface\n\n\nIn the image above, you can see the different labeled points (Hand, Finger1, Joystick1, Joystick2) in the image.\nTo navigate across images, you can use the left/right arrow keys, clicking in the file menu, or click the left/right arrows in the toolbar.",
    "crumbs": [
      "Getting started",
      "Tutorial: Annotate a DeepLabCut dataset"
    ]
  },
  {
    "objectID": "tutorial_deeplabcut.html#specifying-bodyparts",
    "href": "tutorial_deeplabcut.html#specifying-bodyparts",
    "title": "Tutorial: Annotate a DeepLabCut dataset",
    "section": "Specifying bodyparts",
    "text": "Specifying bodyparts\nLet’s look at the bodyparts for this dataset!\nIn the menu, click on: Project &gt; Edit bodyparts\nYou will enter the Bodyparts editor, where you can add or remove bodyparts. It should look like the image below.\n\nIf you have some annotations within your files already, the bodyparts will automatically be populated as in this example. If there are no labels yet, you will need to specify bodyparts.\nYou can drag bodyparts around to change the order for labeling.\nOptionally, you may export the bodyparts to a “bodyparts.toml” file by clicking Export. You can then import this file again to speed up adding bodyparts to a new dataset.",
    "crumbs": [
      "Getting started",
      "Tutorial: Annotate a DeepLabCut dataset"
    ]
  },
  {
    "objectID": "tutorial_deeplabcut.html#annotating-images",
    "href": "tutorial_deeplabcut.html#annotating-images",
    "title": "Tutorial: Annotate a DeepLabCut dataset",
    "section": "Annotating images",
    "text": "Annotating images\nOkay let’s try to annotate!\nPlace keypoints by clicking in the image. The keypoints will be placed following the order of bodyparts. You can move a keypoint by clicking it and dragging it.\nTo mark a keypoint as not missing (not visible), place it in within 50 pixels of the top left corner.\nUseful shortcuts:\n\nselect a keypoint and press “d” (or X icon in toolbar) to delete it\nselect all keypoints by pressing “a”\nselect a keypoint and press “m” to mark as missing (moving to top left corner)",
    "crumbs": [
      "Getting started",
      "Tutorial: Annotate a DeepLabCut dataset"
    ]
  },
  {
    "objectID": "tutorial_deeplabcut.html#exporting-annotations",
    "href": "tutorial_deeplabcut.html#exporting-annotations",
    "title": "Tutorial: Annotate a DeepLabCut dataset",
    "section": "Exporting annotations",
    "text": "Exporting annotations\nTo export your annotations back, follow these steps:\n\nIn the menu, click on: Export &gt; Export Annotations (DeepLabCut format)\nNavigate to your DeepLabCut project: Reaching-Mackenzie-2018-08-30\nGo back within your labeled-data folder, then within the folder you selected (“reachingvideo1” in this case)\nSave your file as “CollectedData_Mackenzie.h5” within the “reachingvideo1” folder, replacing the current labels\n\nFor your own project, you will need to replace “Mackenzie” with the actual scorer name you specified at the top of your DeepLabCut config.yaml\nThat’s it!\n\n\n\n\n\n\nNote\n\n\n\nSimilarly to importing, due to limitations on h5 libraries in javascript, the labels are sent to server to convert them to generate an h5 file. Again, no images are ever sent out of your machine, only labels.",
    "crumbs": [
      "Getting started",
      "Tutorial: Annotate a DeepLabCut dataset"
    ]
  }
]